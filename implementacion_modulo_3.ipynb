{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion Módulo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets/processed_df.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"post\"] = df[\"post\"].astype(str)\n",
    "df[\"title\"] = df[\"title\"].astype(str)\n",
    "df[\"title_post\"] = df[\"title\"] + \" \" + df[\"post\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'artificial|statistics|machinelearning|computervision|rstats|analytics|datasets|computerscience|askstatistics|data|datascience|mlquestions|datasciencejobs|deeplearning|dataengineering|dataanalysis|learnmachinelearning|kaggle|datascienceproject',\n",
       "           re.UNICODE)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_subreddits = re.compile(\"|\".join(list(map(lambda x: x.lower(), df.subreddit.unique()))))\n",
    "\n",
    "re_subreddits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El operador or | nos sirve para definir esta expresión regular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subreddit_mentions(text: str):\n",
    "    re_subreddits = re.compile(\"|\".join(list(map(lambda x: x.lower(), df.subreddit.unique()))))\n",
    "    return \" \".join(re_subreddits.findall(str(text).lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"subreddit_mentions\"] = df[\"title_post\"].apply(lambda x: find_subreddit_mentions(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas url diferentes en el dataset por lo que vamos a intentar incluir caracteres que hemos visto que aparecen también dentro de las urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_extracion(text: str):\n",
    "    re_url = re.compile(r'https?\\:\\/\\/[\\w\\-]+(?:\\.[\\w\\-]+)+(?:[\\/\\w\\-\\.\\?\\=\\&\\#]*)?')\n",
    "    return re.findall(re_url, str(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urls\"] = df[\"title_post\"].apply(url_extracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias formas diferentes de definir un número de teléfono en el dataset. Asi que vamos a crear una expresión regular general en la que se tenga un posible prefijo y diferentes separadores posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_number_extracion(text: str):\n",
    "    re_phone_number = re.compile(r'(?:\\+\\d{1,3}[\\s\\-]?)?[0-9]{3}[\\s\\-]?\\d{3}[\\s\\-]?\\d{4}')\n",
    "    return re_phone_number.findall(str(text).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"phone_numbers\"] = df[\"post\"].apply(lambda x: phone_number_extracion(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>full_link</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmatized_post</th>\n",
       "      <th>stemmed_post</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>title_post</th>\n",
       "      <th>subreddit_mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>phone_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2009-10-28 20:28:27</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Ask Stats: Good Introductory Book (or websites...</td>\n",
       "      <td>ST2K</td>\n",
       "      <td>https://www.reddit.com/r/statistics/comments/9...</td>\n",
       "      <td>9</td>\n",
       "      <td>I own a copy of [Bayesian Statistics: An Intro...</td>\n",
       "      <td>0</td>\n",
       "      <td>copy bayesian statistic introduction little bi...</td>\n",
       "      <td>copi bayesian statist introduct littl bit diff...</td>\n",
       "      <td>copy bayesian statistics introduction little b...</td>\n",
       "      <td>ask stats good introductory book website bayes...</td>\n",
       "      <td>Ask Stats: Good Introductory Book (or websites...</td>\n",
       "      <td>statistics statistics statistics statistics</td>\n",
       "      <td>[http://www.amazon.com/Bayesian-Statistics-Int...</td>\n",
       "      <td>[0340814055]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2010-09-05 05:04:59</td>\n",
       "      <td>artificial</td>\n",
       "      <td>Scientific study proving basically the exact t...</td>\n",
       "      <td>ithkuil</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/d...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.sciencedaily.com/releases/2010/09/1...</td>\n",
       "      <td>0</td>\n",
       "      <td>gt ancestral structure likely group densely pa...</td>\n",
       "      <td>gt ancestr structur like group dens pack cell ...</td>\n",
       "      <td>gt ancestral structure likely group densely pa...</td>\n",
       "      <td>scientific study proving basically exact thing...</td>\n",
       "      <td>Scientific study proving basically the exact t...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>[http://www.sciencedaily.com/releases/2010/09/...</td>\n",
       "      <td>[1009021210]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2010-10-25 22:31:18</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Probability of the game \"Set\"... please help</td>\n",
       "      <td>NaLaurethSulfate</td>\n",
       "      <td>https://www.reddit.com/r/statistics/comments/d...</td>\n",
       "      <td>2</td>\n",
       "      <td>So I am not very good at statistics, have take...</td>\n",
       "      <td>0</td>\n",
       "      <td>good statistic taken college poor high school ...</td>\n",
       "      <td>good statist taken colleg poor high school cov...</td>\n",
       "      <td>good statistics taken college poor high school...</td>\n",
       "      <td>probability game set please help</td>\n",
       "      <td>Probability of the game \"Set\"... please help S...</td>\n",
       "      <td>statistics</td>\n",
       "      <td>[http://www.setgame.com/set/index.html]</td>\n",
       "      <td>[2658227848, 0632911392, 1265822784, 253164556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2011-01-04 08:30:23</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Ask ML: Document ranking with user ratings?</td>\n",
       "      <td>eggbrain</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>10</td>\n",
       "      <td>I've had a fun idea for awhile (not for profit...</td>\n",
       "      <td>0</td>\n",
       "      <td>fun idea awhile profit entertainment keep runn...</td>\n",
       "      <td>fun idea awhil profit entertain keep run barri...</td>\n",
       "      <td>fun idea awhile profit entertainment keep runn...</td>\n",
       "      <td>ask ml document ranking user rating</td>\n",
       "      <td>Ask ML: Document ranking with user ratings? I'...</td>\n",
       "      <td>data data</td>\n",
       "      <td>[http://en.wikipedia.org/wiki/Learning_to_rank...</td>\n",
       "      <td>[9780596529]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2011-01-06 04:51:18</td>\n",
       "      <td>analytics</td>\n",
       "      <td>DotCed - Functional Web Analytics - Tagging, R...</td>\n",
       "      <td>dotced</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/ew...</td>\n",
       "      <td>1</td>\n",
       "      <td>DotCed,a Functional Analytics Consultant, offe...</td>\n",
       "      <td>0</td>\n",
       "      <td>dotced functional analytics consultant offerin...</td>\n",
       "      <td>dotc function analyt consult offer googl analy...</td>\n",
       "      <td>dotced functional analytics consultant offerin...</td>\n",
       "      <td>dotced functional web analytics tagging report...</td>\n",
       "      <td>DotCed - Functional Web Analytics - Tagging, R...</td>\n",
       "      <td>analytics analytics analytics</td>\n",
       "      <td>[]</td>\n",
       "      <td>[919-404-9233]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273985</th>\n",
       "      <td>2022-05-07 06:59:25</td>\n",
       "      <td>dataengineering</td>\n",
       "      <td>Consolidating many data tables from BLS’s API ...</td>\n",
       "      <td>bongdong42O</td>\n",
       "      <td>https://www.reddit.com/r/dataengineering/comme...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey, I’m having trouble figuring out a way to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey trouble figuring way get ton get requested...</td>\n",
       "      <td>hey troubl figur way get ton get request info ...</td>\n",
       "      <td>hey trouble figuring way get ton get requested...</td>\n",
       "      <td>consolidating many data table bls api data fac...</td>\n",
       "      <td>Consolidating many data tables from BLS’s API ...</td>\n",
       "      <td>data data statistics data data data data data</td>\n",
       "      <td>[https://www.bls.gov/help/hlpforma.htm#NB, htt...</td>\n",
       "      <td>[2053000000, 0000019007, 2053000000, 0000033030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274065</th>\n",
       "      <td>2022-05-07 21:02:36</td>\n",
       "      <td>computervision</td>\n",
       "      <td>Morphological Operators usage</td>\n",
       "      <td>ErIndi</td>\n",
       "      <td>https://www.reddit.com/r/computervision/commen...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello everyone!\\n\\n&amp;amp;#x200B;\\n\\nI have post...</td>\n",
       "      <td>0</td>\n",
       "      <td>hello everyone amp posted past project working...</td>\n",
       "      <td>hello everyon amp post past project work curre...</td>\n",
       "      <td>hello everyone amp posted past project working...</td>\n",
       "      <td>morphological operator usage</td>\n",
       "      <td>Morphological Operators usage Hello everyone!\\...</td>\n",
       "      <td>computervision</td>\n",
       "      <td>[https://www.reddit.com/r/computervision/comme...</td>\n",
       "      <td>[7196596905, 1333630640]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274133</th>\n",
       "      <td>2022-05-08 07:29:03</td>\n",
       "      <td>computerscience</td>\n",
       "      <td>Python Programming Character Pairs please help!</td>\n",
       "      <td>Stockolorian</td>\n",
       "      <td>https://www.reddit.com/r/computerscience/comme...</td>\n",
       "      <td>1</td>\n",
       "      <td>Does anyone know how to read a text file in py...</td>\n",
       "      <td>0</td>\n",
       "      <td>anyone know read text file python count many c...</td>\n",
       "      <td>anyon know read text file python count mani ch...</td>\n",
       "      <td>anyone know read text file python count many c...</td>\n",
       "      <td>python programming character pair please help</td>\n",
       "      <td>Python Programming Character Pairs please help...</td>\n",
       "      <td></td>\n",
       "      <td>[https://preview.redd.it/fgqkz4sej6y81.png?wid...</td>\n",
       "      <td>[9734740847]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274139</th>\n",
       "      <td>2022-05-08 08:51:33</td>\n",
       "      <td>datasets</td>\n",
       "      <td>[self-promotion] Hey all, we are running a dat...</td>\n",
       "      <td>Kobedoggg</td>\n",
       "      <td>https://www.reddit.com/r/datasets/comments/ukv...</td>\n",
       "      <td>1</td>\n",
       "      <td>Check out our expressions of interest [LINK](h...</td>\n",
       "      <td>1</td>\n",
       "      <td>check expression interest link li activity lea...</td>\n",
       "      <td>check express interest link li activ learn amp...</td>\n",
       "      <td>check expressions interest link li activity le...</td>\n",
       "      <td>self promotion hey running data challenge vari...</td>\n",
       "      <td>[self-promotion] Hey all, we are running a dat...</td>\n",
       "      <td>data datasets datasets</td>\n",
       "      <td>[https://www.linkedin.com/feed/update/urn]</td>\n",
       "      <td>[6927760517]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274141</th>\n",
       "      <td>2022-05-08 09:01:17</td>\n",
       "      <td>datasets</td>\n",
       "      <td>[self-promotion] Athlete social media dataset ...</td>\n",
       "      <td>Kobedoggg</td>\n",
       "      <td>https://www.reddit.com/r/datasets/comments/ukv...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey all, we are running a data challenge on at...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey running data challenge athlete marketabili...</td>\n",
       "      <td>hey run data challeng athlet market onlin soci...</td>\n",
       "      <td>hey running data challenge athlete marketabili...</td>\n",
       "      <td>self promotion athlete social medium dataset c...</td>\n",
       "      <td>[self-promotion] Athlete social media dataset ...</td>\n",
       "      <td>data data</td>\n",
       "      <td>[https://www.linkedin.com/feed/update/urn]</td>\n",
       "      <td>[6927760517]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4675 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_date        subreddit  \\\n",
       "28      2009-10-28 20:28:27       statistics   \n",
       "202     2010-09-05 05:04:59       artificial   \n",
       "264     2010-10-25 22:31:18       statistics   \n",
       "354     2011-01-04 08:30:23  MachineLearning   \n",
       "359     2011-01-06 04:51:18        analytics   \n",
       "...                     ...              ...   \n",
       "273985  2022-05-07 06:59:25  dataengineering   \n",
       "274065  2022-05-07 21:02:36   computervision   \n",
       "274133  2022-05-08 07:29:03  computerscience   \n",
       "274139  2022-05-08 08:51:33         datasets   \n",
       "274141  2022-05-08 09:01:17         datasets   \n",
       "\n",
       "                                                    title            author  \\\n",
       "28      Ask Stats: Good Introductory Book (or websites...              ST2K   \n",
       "202     Scientific study proving basically the exact t...           ithkuil   \n",
       "264          Probability of the game \"Set\"... please help  NaLaurethSulfate   \n",
       "354           Ask ML: Document ranking with user ratings?          eggbrain   \n",
       "359     DotCed - Functional Web Analytics - Tagging, R...            dotced   \n",
       "...                                                   ...               ...   \n",
       "273985  Consolidating many data tables from BLS’s API ...       bongdong42O   \n",
       "274065                      Morphological Operators usage            ErIndi   \n",
       "274133    Python Programming Character Pairs please help!      Stockolorian   \n",
       "274139  [self-promotion] Hey all, we are running a dat...         Kobedoggg   \n",
       "274141  [self-promotion] Athlete social media dataset ...         Kobedoggg   \n",
       "\n",
       "                                                full_link  score  \\\n",
       "28      https://www.reddit.com/r/statistics/comments/9...      9   \n",
       "202     https://www.reddit.com/r/artificial/comments/d...      0   \n",
       "264     https://www.reddit.com/r/statistics/comments/d...      2   \n",
       "354     https://www.reddit.com/r/MachineLearning/comme...     10   \n",
       "359     https://www.reddit.com/r/analytics/comments/ew...      1   \n",
       "...                                                   ...    ...   \n",
       "273985  https://www.reddit.com/r/dataengineering/comme...      1   \n",
       "274065  https://www.reddit.com/r/computervision/commen...      1   \n",
       "274133  https://www.reddit.com/r/computerscience/comme...      1   \n",
       "274139  https://www.reddit.com/r/datasets/comments/ukv...      1   \n",
       "274141  https://www.reddit.com/r/datasets/comments/ukv...      1   \n",
       "\n",
       "                                                     post  sentiment  \\\n",
       "28      I own a copy of [Bayesian Statistics: An Intro...          0   \n",
       "202     http://www.sciencedaily.com/releases/2010/09/1...          0   \n",
       "264     So I am not very good at statistics, have take...          0   \n",
       "354     I've had a fun idea for awhile (not for profit...          0   \n",
       "359     DotCed,a Functional Analytics Consultant, offe...          0   \n",
       "...                                                   ...        ...   \n",
       "273985  Hey, I’m having trouble figuring out a way to ...          0   \n",
       "274065  Hello everyone!\\n\\n&amp;#x200B;\\n\\nI have post...          0   \n",
       "274133  Does anyone know how to read a text file in py...          0   \n",
       "274139  Check out our expressions of interest [LINK](h...          1   \n",
       "274141  Hey all, we are running a data challenge on at...          0   \n",
       "\n",
       "                                          lemmatized_post  \\\n",
       "28      copy bayesian statistic introduction little bi...   \n",
       "202     gt ancestral structure likely group densely pa...   \n",
       "264     good statistic taken college poor high school ...   \n",
       "354     fun idea awhile profit entertainment keep runn...   \n",
       "359     dotced functional analytics consultant offerin...   \n",
       "...                                                   ...   \n",
       "273985  hey trouble figuring way get ton get requested...   \n",
       "274065  hello everyone amp posted past project working...   \n",
       "274133  anyone know read text file python count many c...   \n",
       "274139  check expression interest link li activity lea...   \n",
       "274141  hey running data challenge athlete marketabili...   \n",
       "\n",
       "                                             stemmed_post  \\\n",
       "28      copi bayesian statist introduct littl bit diff...   \n",
       "202     gt ancestr structur like group dens pack cell ...   \n",
       "264     good statist taken colleg poor high school cov...   \n",
       "354     fun idea awhil profit entertain keep run barri...   \n",
       "359     dotc function analyt consult offer googl analy...   \n",
       "...                                                   ...   \n",
       "273985  hey troubl figur way get ton get request info ...   \n",
       "274065  hello everyon amp post past project work curre...   \n",
       "274133  anyon know read text file python count mani ch...   \n",
       "274139  check express interest link li activ learn amp...   \n",
       "274141  hey run data challeng athlet market onlin soci...   \n",
       "\n",
       "                                               clean_post  \\\n",
       "28      copy bayesian statistics introduction little b...   \n",
       "202     gt ancestral structure likely group densely pa...   \n",
       "264     good statistics taken college poor high school...   \n",
       "354     fun idea awhile profit entertainment keep runn...   \n",
       "359     dotced functional analytics consultant offerin...   \n",
       "...                                                   ...   \n",
       "273985  hey trouble figuring way get ton get requested...   \n",
       "274065  hello everyone amp posted past project working...   \n",
       "274133  anyone know read text file python count many c...   \n",
       "274139  check expressions interest link li activity le...   \n",
       "274141  hey running data challenge athlete marketabili...   \n",
       "\n",
       "                                              clean_title  \\\n",
       "28      ask stats good introductory book website bayes...   \n",
       "202     scientific study proving basically exact thing...   \n",
       "264                      probability game set please help   \n",
       "354                   ask ml document ranking user rating   \n",
       "359     dotced functional web analytics tagging report...   \n",
       "...                                                   ...   \n",
       "273985  consolidating many data table bls api data fac...   \n",
       "274065                       morphological operator usage   \n",
       "274133      python programming character pair please help   \n",
       "274139  self promotion hey running data challenge vari...   \n",
       "274141  self promotion athlete social medium dataset c...   \n",
       "\n",
       "                                               title_post  \\\n",
       "28      Ask Stats: Good Introductory Book (or websites...   \n",
       "202     Scientific study proving basically the exact t...   \n",
       "264     Probability of the game \"Set\"... please help S...   \n",
       "354     Ask ML: Document ranking with user ratings? I'...   \n",
       "359     DotCed - Functional Web Analytics - Tagging, R...   \n",
       "...                                                   ...   \n",
       "273985  Consolidating many data tables from BLS’s API ...   \n",
       "274065  Morphological Operators usage Hello everyone!\\...   \n",
       "274133  Python Programming Character Pairs please help...   \n",
       "274139  [self-promotion] Hey all, we are running a dat...   \n",
       "274141  [self-promotion] Athlete social media dataset ...   \n",
       "\n",
       "                                   subreddit_mentions  \\\n",
       "28        statistics statistics statistics statistics   \n",
       "202                                        artificial   \n",
       "264                                        statistics   \n",
       "354                                         data data   \n",
       "359                     analytics analytics analytics   \n",
       "...                                               ...   \n",
       "273985  data data statistics data data data data data   \n",
       "274065                                 computervision   \n",
       "274133                                                  \n",
       "274139                         data datasets datasets   \n",
       "274141                                      data data   \n",
       "\n",
       "                                                     urls  \\\n",
       "28      [http://www.amazon.com/Bayesian-Statistics-Int...   \n",
       "202     [http://www.sciencedaily.com/releases/2010/09/...   \n",
       "264               [http://www.setgame.com/set/index.html]   \n",
       "354     [http://en.wikipedia.org/wiki/Learning_to_rank...   \n",
       "359                                                    []   \n",
       "...                                                   ...   \n",
       "273985  [https://www.bls.gov/help/hlpforma.htm#NB, htt...   \n",
       "274065  [https://www.reddit.com/r/computervision/comme...   \n",
       "274133  [https://preview.redd.it/fgqkz4sej6y81.png?wid...   \n",
       "274139         [https://www.linkedin.com/feed/update/urn]   \n",
       "274141         [https://www.linkedin.com/feed/update/urn]   \n",
       "\n",
       "                                            phone_numbers  \n",
       "28                                           [0340814055]  \n",
       "202                                          [1009021210]  \n",
       "264     [2658227848, 0632911392, 1265822784, 253164556...  \n",
       "354                                          [9780596529]  \n",
       "359                                        [919-404-9233]  \n",
       "...                                                   ...  \n",
       "273985   [2053000000, 0000019007, 2053000000, 0000033030]  \n",
       "274065                           [7196596905, 1333630640]  \n",
       "274133                                       [9734740847]  \n",
       "274139                                       [6927760517]  \n",
       "274141                                       [6927760517]  \n",
       "\n",
       "[4675 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.phone_numbers.astype(str) != \"[]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código es muy dificil de detectar. Pensamos en capturar las funciones con alguna expresión regular pero entonces no podríamos sacar lo de dentro porque no se tiene ningún indicio de donde acaba la función. Sin embargo, hemos visto que en muchos posts el código se pone entre tildes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_extraction(text:str):\n",
    "    re_code = re.compile(r'```(.*?)```')\n",
    "    return re_code.findall(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_post_code\"] = df[\"title_post\"].apply(lambda x: code_extraction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_ij',\n",
       " 'pi',\n",
       " 'f_i(t)',\n",
       " 'f_i(t)',\n",
       " 'a_ij',\n",
       " 'pi',\n",
       " 'f_i(t)',\n",
       " 'f_i(t)',\n",
       " 'x_i',\n",
       " 'f(x|x_i)',\n",
       " 'f(x|x_i)',\n",
       " 'f(x|x_i)',\n",
       " 'x_i',\n",
       " '--save_resume',\n",
       " 'pairs(iris)',\n",
       " 'lm()',\n",
       " 'aov()',\n",
       " 'waiting = 80',\n",
       " 'waiting = 80',\n",
       " 'dplyr',\n",
       " 'hflights',\n",
       " 'UniqueCarrier',\n",
       " 'UniqueCarrier',\n",
       " 'UniqueCarrier',\n",
       " 'lut',\n",
       " '[ ]',\n",
       " 'UniqueCarrier',\n",
       " 'df',\n",
       " 'if you are a PC',\n",
       " '(message body)',\n",
       " 'aov()',\n",
       " 'anova()',\n",
       " 'fitnet',\n",
       " 'fitnet',\n",
       " 'hiddenSizes',\n",
       " 'trainFcn',\n",
       " 'airport_1,airport_2,flight_volume',\n",
       " \"JFK,O'Hare,1015\",\n",
       " 'INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]*3 -&gt; [FC -&gt; RELU]*2 -&gt; FC',\n",
       " 'description, size',\n",
       " 'hey this is a 15 1/2 inch item with measurementB of 12 inches, 12 1/2',\n",
       " 'description, size',\n",
       " 'measurementB of 12, 12',\n",
       " '12 measurementB, 12',\n",
       " 'max_threshold',\n",
       " 'min_threshold',\n",
       " 'anchors = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " ' Label [ top-left x and y coordinates, bottom-right x and y coordinates] confidence',\n",
       " 'torch.set_default_tensor_type()',\n",
       " 'conda create --name tf_gpu tensorflow-gpu ',\n",
       " 'python',\n",
       " '.load_cifar10()',\n",
       " 'anaconda',\n",
       " 'virtualenv',\n",
       " 'jupyter lab',\n",
       " 'virtualenv',\n",
       " 'flake8',\n",
       " 'Atom',\n",
       " 'virtualenv',\n",
       " 'n_products',\n",
       " 'n_products',\n",
       " 'numpy.vectorize()',\n",
       " 'inspect import signature',\n",
       " '2013-03-01 12:00:59 UTC',\n",
       " './darknet detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights data/dog.jpg',\n",
       " '(1 - (5/6 ^ 25)) = 0.99',\n",
       " 'mydf %&gt;% group_by(x) %&gt;% filter(NA %in% y)',\n",
       " 'mydf %&gt;% group_by(x) %&gt;% filter(!NA %in% y)',\n",
       " '(n choose k) * p^k * (1−p)^(n−k)',\n",
       " 'mtcars %&gt;% ggplot(aes(x=wt))+geom_dotplot()+scale_y_continuous(\"loooooooooooooooong title\")+theme(axis.title.y = element_text(angle=0))',\n",
       " 'mtcars %&gt;% ggplot(aes(x=wt))+geom_dotplot()+scale_y_continuous(\"short title\")+theme(axis.title.y = element_text(angle=0))',\n",
       " 'mtcars %&gt;% ggplot(aes(x=wt))+geom_dotplot()+scale_y_continuous(\"loooooooooooooooong title\")+theme(axis.title.y = element_text(angle=0))',\n",
       " 'mtcars %&gt;% ggplot(aes(x=wt))+geom_dotplot()+scale_y_continuous(\"short title\")+theme(axis.title.y = element_text(angle=0))',\n",
       " '/* insert a comment within a line like this*/',\n",
       " 'lm',\n",
       " 'data %&gt;% filter(gender == 1)',\n",
       " 'devtools::use_testthat()',\n",
       " 'learn = cnn_learner(databunch, models.resnet34, metrics=error_rate)',\n",
       " 'ValueError: bad marshal data (unknown type code)',\n",
       " 'fit_transform()',\n",
       " 'sklearn.preprocessing.PolynomialFeatures',\n",
       " 'poly()',\n",
       " 'poly()',\n",
       " 'fit_transform()',\n",
       " 'fit_transform()',\n",
       " 'sklearn.preprocessing.PolynomialFeatures',\n",
       " 'poly()',\n",
       " 'poly()',\n",
       " 'fit_transform()',\n",
       " 'penalty.factor',\n",
       " 'The second set of models (Figure 1 in the main text) tested whether racial disparities can be predicted by county level differences in race-specific population proportions and violent crime. Because of the high correlation between population size and homicide deaths (Whites, r = .85, Blacks r = .87, and Hispanics, r = .90, see Table S2), we examined the effects of each variable independently, without any officer or civilian predictors. Specifically, in each model civilian race was regressed on a single factor (e.g., percent of county residents that were Black). All predictors were centered and standardized. The variance explained by each set of predictors reflects the degree to which all population or crime variables predict civilian race.',\n",
       " 'c(2)',\n",
       " 'c(2, 1)',\n",
       " 'length(doors) &gt; 3',\n",
       " 'So when I start video chatting, my application, that maybe Skype, starts generating video data packets. However, the data link layer has some restrictions like a packet size cannot be greater than a particular size, let’s say X bytes in total. That implies that the data packets have to be broken down into different chunks and those data packets have to be transmitted chunk by chunk.',\n",
       " '1.0 / sqrt(2.0)',\n",
       " 'sqrt(2.0)',\n",
       " 'git clone ...',\n",
       " 'svd checkout ... ',\n",
       " 'nvidia-smi',\n",
       " \"error can't find:with open(Path('app\\\\\\\\artifacts\\\\\\\\model.pickle'), 'rb')\",\n",
       " 'FileNotFoundError: [Errno 2] No such file or directory: \\'app\\\\\\\\\\\\\\\\artifacts\\\\\\\\\\\\\\\\model.pickle\\'\"',\n",
       " \"error can't find:with open(Path('app\\\\\\\\artifacts\\\\\\\\model.pickle'), 'rb')\",\n",
       " 'FileNotFoundError: [Errno 2] No such file or directory: \\'app\\\\\\\\\\\\\\\\artifacts\\\\\\\\\\\\\\\\model.pickle\\'\"',\n",
       " \"error can't find:with open(Path('app\\\\\\\\artifacts\\\\\\\\model.pickle'), 'rb')\",\n",
       " 'FileNotFoundError: [Errno 2] No such file or directory: \\'app\\\\\\\\\\\\\\\\artifacts\\\\\\\\\\\\\\\\model.pickle\\'\"',\n",
       " '% Soil Porosity: 33.33%, 31.66%, 35.67%',\n",
       " '% field capacity: 53.98%, 44.30%, 10.26%',\n",
       " '  Column {data-width=600} -----------------------------------------------------------------------  ### Species  ',\n",
       " '   Column {data-width=400} -----------------------------------------------------------------------  ### Species (Quantile)  ',\n",
       " '{r} figure(width = NULL, height = NULL) %&gt;%   ly_points(Sepal.Length, Sepal.Width, data = iris,     color = Petal.Width) ',\n",
       " 'x = 10',\n",
       " \"ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\",\n",
       " 'X = np.array(ct.fit_transform(X))',\n",
       " \"ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\",\n",
       " 'X = np.array(ct.fit_transform(X))',\n",
       " 'sudo apt upgrade',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash',\n",
       " '!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash',\n",
       " '! pip install nlu pyspark==3.0.1',\n",
       " 'Lookup Table &gt; Temp Conv64 &gt; Convblock64, Convblock128 &gt; Convblock128 &gt; Convblock256 &gt; Convblock256 &gt; Convblock512 &gt; Convblock512 &gt; k-max pooling &gt; 2X fc(2048) &gt; output layer',\n",
       " 'cor(Dataset$VariableA, Dataset$Post)',\n",
       " 'data.frame(x = c(\"no\",\"yee\",\"yes\")) %&gt;% filter(grepl(x = x,pattern = \"ye\")) %&gt;% filter(!grepl(x = x,pattern = \"yes\"))',\n",
       " 'data.frame(x = c(\"no\",\"yee\",\"yes\")) %&gt;% filter(grepl(x = x,pattern = \"ye!s\"))',\n",
       " 'ode-python',\n",
       " 'myData %&gt;% rowwise() %&gt;% mutate(blanks = across(.cols = everything(),length(is.na(.))))',\n",
       " 'result.write..',\n",
       " 'result.cache().count()',\n",
       " 'clf.fit(train_data, train_labels).predict_proba(test_data)',\n",
       " 'top_k=400000',\n",
       " 'vocab.txt',\n",
       " 'vocab.txt',\n",
       " 'self.vectors',\n",
       " 'batch',\n",
       " 'class label (0...9)',\n",
       " 'dataset label (0...3)',\n",
       " 'score = (tp + fp) + (tp + fn) / (tp +fp)',\n",
       " 'score = (actual_turnout - predicted_turnout) / actual_turnout',\n",
       " 'dbt_utils.get_relations_by_pattern',\n",
       " \"{% set ga_relations = dbt_utils.get_relations_by_pattern('%-ga, 'sessions') %}\",\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title_post_code\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como si se ha capturado algún código pero no es muy exacto el sistema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
