{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2298d75",
   "metadata": {},
   "source": [
    "# Implementación Módulo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccb586",
   "metadata": {},
   "source": [
    "Toda la parte de testing se realizará en cada notebook de la implementación por simplicidad ya que de la otra forma el archivo core.py contendría demasiada información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b02a38abff99230",
   "metadata": {},
   "source": [
    "# Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:08.217504Z",
     "start_time": "2024-12-11T09:59:07.007747Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc3ace39e436e4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:08.232182Z",
     "start_time": "2024-12-11T09:59:08.226129Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_processing(x):\n",
    "    resul = np.nan\n",
    "    if x == \"NEGATIVE\":\n",
    "        resul = 0\n",
    "    elif x == \"POSITIVE\":\n",
    "        resul = 1\n",
    "    return resul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245a9605fd6db91",
   "metadata": {},
   "source": [
    "### Cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0620afb01e7b898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:15.936038Z",
     "start_time": "2024-12-11T09:59:08.249617Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets/reddit_database_sentiment.csv\", \n",
    "                 sep=\";\", \n",
    "                 parse_dates=[\"created_date\"],\n",
    "                 usecols=[\"created_date\", \"subreddit\", \"title\", \"author\", \"full_link\", \"score\", \"post\", \"sentiment\"],\n",
    "                 converters={\"sentiment\": lambda x: sentiment_processing(x)},\n",
    "                 index_col=\"created_date\", \n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e08b6cca56c5bb24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:16.910973Z",
     "start_time": "2024-12-11T09:59:15.976527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo ocupa: 386445993 Bytes\n"
     ]
    }
   ],
   "source": [
    "print(f\"El archivo ocupa: {df.memory_usage(deep=True).sum()} Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f852de8d14ce53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:17.006400Z",
     "start_time": "2024-12-11T09:59:16.961383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>full_link</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-11 19:47:22</th>\n",
       "      <td>analytics</td>\n",
       "      <td>So what do you guys all do related to analytic...</td>\n",
       "      <td>xtom</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/b0...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>There's a lot of reasons to want to know all t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-04 20:17:26</th>\n",
       "      <td>analytics</td>\n",
       "      <td>Google's Invasive, non-Anonymized Ad Targeting...</td>\n",
       "      <td>xtom</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/b9...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I'm cross posting this from /r/cyberlaw, hopef...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06 04:51:18</th>\n",
       "      <td>analytics</td>\n",
       "      <td>DotCed - Functional Web Analytics - Tagging, R...</td>\n",
       "      <td>dotced</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/ew...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DotCed,a Functional Analytics Consultant, offe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-19 11:45:30</th>\n",
       "      <td>analytics</td>\n",
       "      <td>Program Details - Data Analytics Course</td>\n",
       "      <td>iqrconsulting</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/f5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Here is the program details of the data analyt...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-19 21:52:28</th>\n",
       "      <td>analytics</td>\n",
       "      <td>potential job in web analytics... need to anal...</td>\n",
       "      <td>therewontberiots</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/f5...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>i decided grad school (physics) was not for me...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-07 21:38:52</th>\n",
       "      <td>rstats</td>\n",
       "      <td>Help interpretting lmer model output</td>\n",
       "      <td>seeking-stillness</td>\n",
       "      <td>https://www.reddit.com/r/rstats/comments/ukjiy...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hello! I am wonder how the following output wo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-07 22:13:52</th>\n",
       "      <td>rstats</td>\n",
       "      <td>Medical stats book with R</td>\n",
       "      <td>Sweaty_Catch_4275</td>\n",
       "      <td>https://www.reddit.com/r/rstats/comments/ukk7u...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Can anybody recommend me a book with medical s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 00:38:50</th>\n",
       "      <td>rstats</td>\n",
       "      <td>Markov chains with unequal sequence lengths</td>\n",
       "      <td>sebelly</td>\n",
       "      <td>https://www.reddit.com/r/rstats/comments/ukn1i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm trying to build a simple Markov chain. I h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 01:19:00</th>\n",
       "      <td>rstats</td>\n",
       "      <td>view all available Rcpp::plugins</td>\n",
       "      <td>BOBOLIU</td>\n",
       "      <td>https://www.reddit.com/r/rstats/comments/uknuh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>How do I view all available Rcpp::plugins? Tha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 01:19:34</th>\n",
       "      <td>rstats</td>\n",
       "      <td>Print only loadings in factanal</td>\n",
       "      <td>artgotframed</td>\n",
       "      <td>https://www.reddit.com/r/rstats/comments/uknuw...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hi everybody,\\n\\nI am currently doing a factor...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274239 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     subreddit  \\\n",
       "created_date                     \n",
       "2010-02-11 19:47:22  analytics   \n",
       "2010-03-04 20:17:26  analytics   \n",
       "2011-01-06 04:51:18  analytics   \n",
       "2011-01-19 11:45:30  analytics   \n",
       "2011-01-19 21:52:28  analytics   \n",
       "...                        ...   \n",
       "2022-05-07 21:38:52     rstats   \n",
       "2022-05-07 22:13:52     rstats   \n",
       "2022-05-08 00:38:50     rstats   \n",
       "2022-05-08 01:19:00     rstats   \n",
       "2022-05-08 01:19:34     rstats   \n",
       "\n",
       "                                                                 title  \\\n",
       "created_date                                                             \n",
       "2010-02-11 19:47:22  So what do you guys all do related to analytic...   \n",
       "2010-03-04 20:17:26  Google's Invasive, non-Anonymized Ad Targeting...   \n",
       "2011-01-06 04:51:18  DotCed - Functional Web Analytics - Tagging, R...   \n",
       "2011-01-19 11:45:30            Program Details - Data Analytics Course   \n",
       "2011-01-19 21:52:28  potential job in web analytics... need to anal...   \n",
       "...                                                                ...   \n",
       "2022-05-07 21:38:52               Help interpretting lmer model output   \n",
       "2022-05-07 22:13:52                          Medical stats book with R   \n",
       "2022-05-08 00:38:50        Markov chains with unequal sequence lengths   \n",
       "2022-05-08 01:19:00                   view all available Rcpp::plugins   \n",
       "2022-05-08 01:19:34                    Print only loadings in factanal   \n",
       "\n",
       "                                author  \\\n",
       "created_date                             \n",
       "2010-02-11 19:47:22               xtom   \n",
       "2010-03-04 20:17:26               xtom   \n",
       "2011-01-06 04:51:18             dotced   \n",
       "2011-01-19 11:45:30      iqrconsulting   \n",
       "2011-01-19 21:52:28   therewontberiots   \n",
       "...                                ...   \n",
       "2022-05-07 21:38:52  seeking-stillness   \n",
       "2022-05-07 22:13:52  Sweaty_Catch_4275   \n",
       "2022-05-08 00:38:50            sebelly   \n",
       "2022-05-08 01:19:00            BOBOLIU   \n",
       "2022-05-08 01:19:34       artgotframed   \n",
       "\n",
       "                                                             full_link  score  \\\n",
       "created_date                                                                    \n",
       "2010-02-11 19:47:22  https://www.reddit.com/r/analytics/comments/b0...    7.0   \n",
       "2010-03-04 20:17:26  https://www.reddit.com/r/analytics/comments/b9...    2.0   \n",
       "2011-01-06 04:51:18  https://www.reddit.com/r/analytics/comments/ew...    1.0   \n",
       "2011-01-19 11:45:30  https://www.reddit.com/r/analytics/comments/f5...    0.0   \n",
       "2011-01-19 21:52:28  https://www.reddit.com/r/analytics/comments/f5...    2.0   \n",
       "...                                                                ...    ...   \n",
       "2022-05-07 21:38:52  https://www.reddit.com/r/rstats/comments/ukjiy...    1.0   \n",
       "2022-05-07 22:13:52  https://www.reddit.com/r/rstats/comments/ukk7u...    1.0   \n",
       "2022-05-08 00:38:50  https://www.reddit.com/r/rstats/comments/ukn1i...    1.0   \n",
       "2022-05-08 01:19:00  https://www.reddit.com/r/rstats/comments/uknuh...    1.0   \n",
       "2022-05-08 01:19:34  https://www.reddit.com/r/rstats/comments/uknuw...    1.0   \n",
       "\n",
       "                                                                  post  \\\n",
       "created_date                                                             \n",
       "2010-02-11 19:47:22  There's a lot of reasons to want to know all t...   \n",
       "2010-03-04 20:17:26  I'm cross posting this from /r/cyberlaw, hopef...   \n",
       "2011-01-06 04:51:18  DotCed,a Functional Analytics Consultant, offe...   \n",
       "2011-01-19 11:45:30  Here is the program details of the data analyt...   \n",
       "2011-01-19 21:52:28  i decided grad school (physics) was not for me...   \n",
       "...                                                                ...   \n",
       "2022-05-07 21:38:52  Hello! I am wonder how the following output wo...   \n",
       "2022-05-07 22:13:52  Can anybody recommend me a book with medical s...   \n",
       "2022-05-08 00:38:50  I'm trying to build a simple Markov chain. I h...   \n",
       "2022-05-08 01:19:00  How do I view all available Rcpp::plugins? Tha...   \n",
       "2022-05-08 01:19:34  Hi everybody,\\n\\nI am currently doing a factor...   \n",
       "\n",
       "                     sentiment  \n",
       "created_date                    \n",
       "2010-02-11 19:47:22        0.0  \n",
       "2010-03-04 20:17:26        0.0  \n",
       "2011-01-06 04:51:18        0.0  \n",
       "2011-01-19 11:45:30        0.0  \n",
       "2011-01-19 21:52:28        1.0  \n",
       "...                        ...  \n",
       "2022-05-07 21:38:52        0.0  \n",
       "2022-05-07 22:13:52        1.0  \n",
       "2022-05-08 00:38:50        0.0  \n",
       "2022-05-08 01:19:00        1.0  \n",
       "2022-05-08 01:19:34        0.0  \n",
       "\n",
       "[274239 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9283a769b0711063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:17.324292Z",
     "start_time": "2024-12-11T09:59:17.122188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 274239 entries, 2010-02-11 19:47:22 to 2022-05-08 01:19:34\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   subreddit  274209 non-null  object \n",
      " 1   title      274209 non-null  object \n",
      " 2   author     274209 non-null  object \n",
      " 3   full_link  274209 non-null  object \n",
      " 4   score      274209 non-null  float64\n",
      " 5   post       274209 non-null  object \n",
      " 6   sentiment  274203 non-null  float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d53ecfab0a273",
   "metadata": {},
   "source": [
    "### Tratamiento de valores nulos y no correspondidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3446f866dac43",
   "metadata": {},
   "source": [
    "Hay valores string y nulos en el índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e54c311061bdb84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:17.914886Z",
     "start_time": "2024-12-11T09:59:17.412903Z"
    }
   },
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "df.drop(df[df.index.isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9f6ee223dd95e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:18.035229Z",
     "start_time": "2024-12-11T09:59:17.924423Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "806a7edb610bac1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:18.088929Z",
     "start_time": "2024-12-11T09:59:18.062461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>full_link</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-06-23 16:50:44</th>\n",
       "      <td>artificial</td>\n",
       "      <td>Are worms intelligent?</td>\n",
       "      <td>ithkuil</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/8...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This is me trying to start thinking about my o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 23:59:58</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Is a masters in Statistics worth it?</td>\n",
       "      <td>nazghash</td>\n",
       "      <td>https://www.reddit.com/r/statistics/comments/8...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>I'm working on an MS in Statistics at a state ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-05 07:39:04</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Books/resources that discuss change point anal...</td>\n",
       "      <td>Abhishek_Ghose</td>\n",
       "      <td>https://www.reddit.com/r/statistics/comments/8...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I am looking for books/online-resources that d...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-07 03:58:15</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Pari-Mutuel Horse Racing Pool?</td>\n",
       "      <td>painperdu</td>\n",
       "      <td>https://www.reddit.com/r/statistics/comments/8...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anyone study angles on how to beat a pari-mutu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-21 16:55:04</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Ask Stats: I got a BS in stats and I'm startin...</td>\n",
       "      <td>mathsuu</td>\n",
       "      <td>https://www.reddit.com/r/statistics/comments/9...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I should mention that I know SAS and R pretty ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 18:00:10</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>[D] Simple Questions Thread</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Please post your questions here instead of cre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 18:13:53</th>\n",
       "      <td>computerscience</td>\n",
       "      <td>Question about binary code and files identity</td>\n",
       "      <td>pc0999</td>\n",
       "      <td>https://www.reddit.com/r/computerscience/comme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hi, \\n\\nI am a philosophy student writing an e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 18:15:56</th>\n",
       "      <td>dataengineering</td>\n",
       "      <td>Creating a data pipeline in AWS</td>\n",
       "      <td>OinkOink9</td>\n",
       "      <td>https://www.reddit.com/r/dataengineering/comme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I want to create a data pipeline in AWS (free-...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 19:01:40</th>\n",
       "      <td>dataengineering</td>\n",
       "      <td>I have a free pass to MLOps World in Toronto C...</td>\n",
       "      <td>Quiet_Basket_9699</td>\n",
       "      <td>https://www.reddit.com/r/dataengineering/comme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You can see workshops etc www.MLOps world.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-08 19:07:51</th>\n",
       "      <td>dataengineering</td>\n",
       "      <td>How do you all seed and promote data from data...</td>\n",
       "      <td>leowhite11</td>\n",
       "      <td>https://www.reddit.com/r/dataengineering/comme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hello,\\n\\nMy company is building a data wareho...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274209 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           subreddit  \\\n",
       "created_date                           \n",
       "2009-06-23 16:50:44       artificial   \n",
       "2009-07-01 23:59:58       statistics   \n",
       "2009-07-05 07:39:04       statistics   \n",
       "2009-07-07 03:58:15       statistics   \n",
       "2009-07-21 16:55:04       statistics   \n",
       "...                              ...   \n",
       "2022-05-08 18:00:10  MachineLearning   \n",
       "2022-05-08 18:13:53  computerscience   \n",
       "2022-05-08 18:15:56  dataengineering   \n",
       "2022-05-08 19:01:40  dataengineering   \n",
       "2022-05-08 19:07:51  dataengineering   \n",
       "\n",
       "                                                                 title  \\\n",
       "created_date                                                             \n",
       "2009-06-23 16:50:44                             Are worms intelligent?   \n",
       "2009-07-01 23:59:58               Is a masters in Statistics worth it?   \n",
       "2009-07-05 07:39:04  Books/resources that discuss change point anal...   \n",
       "2009-07-07 03:58:15                     Pari-Mutuel Horse Racing Pool?   \n",
       "2009-07-21 16:55:04  Ask Stats: I got a BS in stats and I'm startin...   \n",
       "...                                                                ...   \n",
       "2022-05-08 18:00:10                        [D] Simple Questions Thread   \n",
       "2022-05-08 18:13:53      Question about binary code and files identity   \n",
       "2022-05-08 18:15:56                    Creating a data pipeline in AWS   \n",
       "2022-05-08 19:01:40  I have a free pass to MLOps World in Toronto C...   \n",
       "2022-05-08 19:07:51  How do you all seed and promote data from data...   \n",
       "\n",
       "                                author  \\\n",
       "created_date                             \n",
       "2009-06-23 16:50:44            ithkuil   \n",
       "2009-07-01 23:59:58           nazghash   \n",
       "2009-07-05 07:39:04     Abhishek_Ghose   \n",
       "2009-07-07 03:58:15          painperdu   \n",
       "2009-07-21 16:55:04            mathsuu   \n",
       "...                                ...   \n",
       "2022-05-08 18:00:10      AutoModerator   \n",
       "2022-05-08 18:13:53             pc0999   \n",
       "2022-05-08 18:15:56          OinkOink9   \n",
       "2022-05-08 19:01:40  Quiet_Basket_9699   \n",
       "2022-05-08 19:07:51         leowhite11   \n",
       "\n",
       "                                                             full_link  score  \\\n",
       "created_date                                                                    \n",
       "2009-06-23 16:50:44  https://www.reddit.com/r/artificial/comments/8...    3.0   \n",
       "2009-07-01 23:59:58  https://www.reddit.com/r/statistics/comments/8...    8.0   \n",
       "2009-07-05 07:39:04  https://www.reddit.com/r/statistics/comments/8...    2.0   \n",
       "2009-07-07 03:58:15  https://www.reddit.com/r/statistics/comments/8...    0.0   \n",
       "2009-07-21 16:55:04  https://www.reddit.com/r/statistics/comments/9...    0.0   \n",
       "...                                                                ...    ...   \n",
       "2022-05-08 18:00:10  https://www.reddit.com/r/MachineLearning/comme...    1.0   \n",
       "2022-05-08 18:13:53  https://www.reddit.com/r/computerscience/comme...    1.0   \n",
       "2022-05-08 18:15:56  https://www.reddit.com/r/dataengineering/comme...    1.0   \n",
       "2022-05-08 19:01:40  https://www.reddit.com/r/dataengineering/comme...    1.0   \n",
       "2022-05-08 19:07:51  https://www.reddit.com/r/dataengineering/comme...    1.0   \n",
       "\n",
       "                                                                  post  \\\n",
       "created_date                                                             \n",
       "2009-06-23 16:50:44  This is me trying to start thinking about my o...   \n",
       "2009-07-01 23:59:58  I'm working on an MS in Statistics at a state ...   \n",
       "2009-07-05 07:39:04  I am looking for books/online-resources that d...   \n",
       "2009-07-07 03:58:15  Anyone study angles on how to beat a pari-mutu...   \n",
       "2009-07-21 16:55:04  I should mention that I know SAS and R pretty ...   \n",
       "...                                                                ...   \n",
       "2022-05-08 18:00:10  Please post your questions here instead of cre...   \n",
       "2022-05-08 18:13:53  Hi, \\n\\nI am a philosophy student writing an e...   \n",
       "2022-05-08 18:15:56  I want to create a data pipeline in AWS (free-...   \n",
       "2022-05-08 19:01:40      You can see workshops etc www.MLOps world.com   \n",
       "2022-05-08 19:07:51  Hello,\\n\\nMy company is building a data wareho...   \n",
       "\n",
       "                     sentiment  \n",
       "created_date                    \n",
       "2009-06-23 16:50:44        0.0  \n",
       "2009-07-01 23:59:58        0.0  \n",
       "2009-07-05 07:39:04        1.0  \n",
       "2009-07-07 03:58:15        0.0  \n",
       "2009-07-21 16:55:04        0.0  \n",
       "...                        ...  \n",
       "2022-05-08 18:00:10        0.0  \n",
       "2022-05-08 18:13:53        0.0  \n",
       "2022-05-08 18:15:56        0.0  \n",
       "2022-05-08 19:01:40        1.0  \n",
       "2022-05-08 19:07:51        0.0  \n",
       "\n",
       "[274209 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19ded9627d0c4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23826b3b028934ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:18.443230Z",
     "start_time": "2024-12-11T09:59:18.212448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    0\n",
       "title        0\n",
       "author       0\n",
       "full_link    0\n",
       "score        0\n",
       "post         0\n",
       "sentiment    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90f99c034165e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:59:24.239661Z",
     "start_time": "2024-12-11T09:59:24.064296Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(df[df.sentiment.isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d5b28343bc411",
   "metadata": {},
   "source": [
    "### Tratamiento de tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dd1c96961c2921d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:27.562273Z",
     "start_time": "2024-12-11T09:34:27.555409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit     object\n",
       "title         object\n",
       "author        object\n",
       "full_link     object\n",
       "score        float64\n",
       "post          object\n",
       "sentiment    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc12ed159e24952",
   "metadata": {},
   "source": [
    "#### Valores numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a803ba718bc3f289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:27.794447Z",
     "start_time": "2024-12-11T09:34:27.789140Z"
    }
   },
   "outputs": [],
   "source": [
    "number_cols = df.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cd93c04dcdaeed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:27.904948Z",
     "start_time": "2024-12-11T09:34:27.882361Z"
    }
   },
   "outputs": [],
   "source": [
    "df[number_cols] = df[number_cols].apply(pd.to_numeric, downcast=\"unsigned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cc1388aafb1ab77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:28.302815Z",
     "start_time": "2024-12-11T09:34:27.932588Z"
    }
   },
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=\"object\").columns\n",
    "df[object_cols] = df[object_cols].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ebf0dde65d2808b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:28.378547Z",
     "start_time": "2024-12-11T09:34:28.340023Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"subreddit\"] = df[\"subreddit\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a3a8c6be35ce183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:28.432874Z",
     "start_time": "2024-12-11T09:34:28.424970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit          category\n",
       "title        string[python]\n",
       "author       string[python]\n",
       "full_link    string[python]\n",
       "score                uint16\n",
       "post         string[python]\n",
       "sentiment             uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "734adf0a253af76b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:29.510488Z",
     "start_time": "2024-12-11T09:34:28.520071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo ocupa: 349751009 Bytes\n"
     ]
    }
   ],
   "source": [
    "print(f\"El archivo ocupa: {df.memory_usage(deep=True).sum()} Bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f562c",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34acbb31ee1a76cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:31.284911Z",
     "start_time": "2024-12-11T09:34:29.577909Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import emoji\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0d1901f95c2d5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:31.297853Z",
     "start_time": "2024-12-11T09:34:31.292800Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_post(text: str, root=\"lemmatize\") -> str:\n",
    "\n",
    "    # Convertimos a minúsculas\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Convertimos emojis a texto\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    # Expandimos contracciones\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # Eliminamos URLs\n",
    "    text = re.sub(r'((http|https)\\:\\/\\/)?([a-zA-Z0-9\\.\\-]+)\\.([a-zA-Z]{2,})(\\/[a-zA-Z0-9\\#\\?\\&\\=\\.\\_\\-]*)*', '', text)\n",
    "\n",
    "    # Eliminamos caracteres especiales y dígitos\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "\n",
    "    # Tokenizamos y eliminamos stopwords\n",
    "    words = word_tokenize(text.strip())\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatizamos, stemmizamos o no hacemos nada dependiendo del valor de root\n",
    "\n",
    "    if root == \"lemmatize\":\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    elif root == \"stem\":\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    elif root == None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"root debe ser 'lemmatize', 'stem' o None\")\n",
    "    \n",
    "    return \" \". join([word for word in words if  21 > len(word) > 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b4990d3696217b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:34:31.328759Z",
     "start_time": "2024-12-11T09:34:31.317194Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8768b2e",
   "metadata": {},
   "source": [
    "## Simplificamos las operaciones anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17f9e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df.dtypes.to_dict()\n",
    "del types[\"score\"]\n",
    "del types[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8495582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_properly():\n",
    "    df = pd.read_csv(\"Datasets/reddit_database_sentiment.csv\", \n",
    "                    sep=\";\", \n",
    "                    parse_dates=[\"created_date\"], \n",
    "                    usecols=[\"created_date\", \"subreddit\", \"title\", \"author\", \"full_link\", \n",
    "                            \"score\", \"post\", \"sentiment\"], \n",
    "                    converters={\"sentiment\": lambda x: sentiment_processing(x)}, \n",
    "                    dtype=types,\n",
    "                    index_col=\"created_date\", \n",
    "                    low_memory=False)\n",
    "\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df.drop(df[df.index.isna()].index, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.drop(df[df.sentiment.isna()].index, inplace=True)\n",
    "    df[\"score\"] = pd.to_numeric(df[\"score\"], downcast=\"unsigned\")\n",
    "    df[\"sentiment\"] = pd.to_numeric(df[\"sentiment\"], downcast=\"unsigned\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c630538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv_properly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1395eaef1e8bfd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:45:31.346880Z",
     "start_time": "2024-12-11T09:34:31.346119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274203/274203 [00:25<00:00, 10716.65it/s]\n",
      "100%|██████████| 274203/274203 [00:23<00:00, 11721.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#Realizamos el preprocesamiento en nuevas columnas\n",
    "\n",
    "preprocess_post = np.vectorize(preprocess_post)\n",
    "df[\"lemmatized_post\"] = tqdm(preprocess_post(df.post))\n",
    "df[\"stemmed_post\"] = tqdm(preprocess_post(df.post, root=\"stem\"))\n",
    "df[\"clean_post\"] = preprocess_post(df.post, root=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1bdd3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_title\"] = preprocess_post(df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a2c3b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_date\n",
       "2009-06-23 16:50:44    trying start thinking understanding intelligen...\n",
       "2009-07-01 23:59:58    working statistic state school curious useful ...\n",
       "2009-07-05 07:39:04    looking book online resource discus change poi...\n",
       "2009-07-07 03:58:15    anyone study angle beat pari mutuel pool horse...\n",
       "2009-07-21 16:55:04    mention know sa pretty well sa certified yet t...\n",
       "                                             ...                        \n",
       "2022-05-08 18:00:10    please post question instead creating new thre...\n",
       "2022-05-08 18:13:53    hi philosophy student writing essay digital th...\n",
       "2022-05-08 18:15:56    want create data pipeline aws free tier accoun...\n",
       "2022-05-08 19:01:40                                     see workshop etc\n",
       "2022-05-08 19:07:51    hello company building data warehouse currentl...\n",
       "Name: lemmatized_post, Length: 274203, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lemmatized_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f60f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zv/3bfm85yn3sj8cxxj_6gghk400000gr/T/ipykernel_22901/1885788841.py:1: FutureWarning: Categorical.to_list is deprecated and will be removed in a future version. Use obj.tolist() instead\n",
      "  df.subreddit.unique().to_list()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artificial',\n",
       " 'statistics',\n",
       " 'MachineLearning',\n",
       " 'computervision',\n",
       " 'rstats',\n",
       " 'analytics',\n",
       " 'datasets',\n",
       " 'computerscience',\n",
       " 'AskStatistics',\n",
       " 'data',\n",
       " 'datascience',\n",
       " 'MLQuestions',\n",
       " 'DataScienceJobs',\n",
       " 'deeplearning',\n",
       " 'dataengineering',\n",
       " 'dataanalysis',\n",
       " 'learnmachinelearning',\n",
       " 'kaggle',\n",
       " 'datascienceproject']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subreddit.unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "339de2ea22ace0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T09:45:37.367852Z",
     "start_time": "2024-12-11T09:45:31.496664Z"
    }
   },
   "outputs": [],
   "source": [
    "#Nos guardamos el dataset procesado en un nuevo archivo\n",
    "df.to_csv(\"Datasets/processed_df.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
